{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Particle Swarm Optimization (PSO)\n",
    "\n",
    "PSO is a population-based optimization tool, which could be implemented and applied easily to solve various function optimization problems, or the problems that can be transformed to function optimization problems. As an algorithm, the main strength of PSO is its fast convergence. For applying PSO successfully, one of the key issues is finding how to map the problem solution into the PSO particle, which directly affects its feasibility and performance.\n",
    "\n",
    "Since its original proposal in 1995 by J. Kennedy an R.Eberhart, Particle Swarm Optimization became very popular due his continue optimization process allowing variations to multi targets and more. \n",
    "\n",
    "The algorithm generates a certain number of particles, afterwards, it continously moves them in the search of best solution, each particle moves with a certain velocity calculated in every iteration. Each particle’s movement has the influence of his own best known position and also the best known position among all particles. The expected result is that the particle swarm converge to the best solution. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Canonical Model\n",
    "The canonical PSO model consists of a swarm of particles. The algorithm takes the following steps\n",
    " - particles are initialized with a population of random candidate solutions\n",
    " - move iteratively through the d-dimension problem space to search the new solutions\n",
    " - there is a fitness function, f, which represents a certain qualities measure\n",
    " - each particle has a position represented by a position-vector $x_i$ and a velocity represented by a velocity-vector $v_i$ \n",
    "- each particle remembers its own best position so far $x_i^\\#$, and the best position-vector among the swarm so far $x^*$\n",
    "\n",
    "During the iteration time $t$, the update of the velocity from the previous velocity to the new velocity is determined by \n",
    "$$ v_{ij}(t+1) = w v_{ij}(t) + c_1 r_1 (x^\\#_{ij}(t) − x_{ij}(t)) + c_2 r_2 (x^∗_j(t) − x_{ij}(t)) \\tag{1}$$\n",
    "\n",
    "Let’s take a closer look to the equation that defines the velocity of the next iteration of a particle dimension:\n",
    "* $v_{ij}(t+1)$ is the next iteration velocity\n",
    "* $w$ is an inertial parameter. This parameter affects the movement propagation given by the last velocity value.\n",
    "* $c_1$ and $c_2$ are positive constants representing the acceleration coefficients. $c_1$, called as coefficient of the self-recognition component,  gives the importance of personal best value. $c_2$, called as coefficient of the social component, is the importance of social best value.\n",
    "* $x^\\#_{ij}(t)$ is the best individual position and $x^*_{ij}(t)$ is the best position of all particles. In the equation, is measured the distance of each of these parameters to the particle’s actual position.\n",
    "* $r_1$ and $r_2$ are random numbers where 0 ≤ rand ≤ 1 and they control the influence of each value: Social and individual as shown below. They are used to maintain the diversity of the population, and are uniformly distributed in the interval $[0,1]$ for the $j$-th dimension of the $i$-th particle. \n",
    "\n",
    "A particle decides where to move next, considering its own experience, which is the memory of its best past position, and the experience of its most successful particle in the swarm. In the particle swarm model, the particle searches the solutions in the problem space with a range $[−s, s]$. \n",
    "￼\n",
    "The new position is then determined by the sum of the previous position and the new velocity by \n",
    "$$ x_{ij}(t+1) = x_{ij}(t) + v_{ij}(t + 1) \\tag{2}$$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Algorithm\n",
    "\n",
    "Let’s observe the pseudo algorithm:\n",
    "\n",
    "At first, it initializes the particles’ positions with a random uniform distribution within a permissible range for all its dimensions (Some problems require handling to several dimensions). \n",
    "\n",
    "After that, for each particle, it calculates its fitness value and compared with his own best position (The p_best value (x#) is the best position of that specific particle has ever been) and then it chooses the best position of all particles in g_best (x*).\n",
    "\n",
    "Finally, the position and velocity are updated accordingly\n",
    "\n",
    "---\n",
    "Algorithm 1 Particle Swarm Optimization Algorithm\n",
    "``` \n",
    "    1. Initialize the size of the particle swarm n, and other parameters\n",
    "    2. Initialize the positions and the velocities for all the particles randomly\n",
    "    3. While (the end criterion is not met) do\n",
    "        3.1 t=t+1\n",
    "        3.2 Calculate the fitness value of each particle\n",
    "        3.3 x∗ = min(f(x∗(t−1)),f(x1(t)),f(x2(t)),···,f(xi(t)),···,f(xn(t)))\n",
    "        3.4 For i = 1 to n\n",
    "            3.4.1 xi# (t)=min(f(xi# (t−1)),f(xi(t)) \n",
    "            3.4.2 For j = 1 to Dimension\n",
    "                3.4.2.1 Update the j-th dimension value of xi and vi\n",
    "            3.4.3 Next j \n",
    "        3.4 Next i\n",
    "    4. End While\n",
    "```\n",
    "\n",
    "The end criteria are usually one of the following:\n",
    "- Maximum number of iterations: the optimization process is terminated after a fixed number of iterations, for example, 1000 iterations.\n",
    "- Number of iterations without improvement: the optimization process is terminated after some fixed number of iterations without any improve-ment.\n",
    "- Minimum objective function error: the error between the obtained objective function value and the best fitness value is less than a pre-fixed anticipated threshold."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "source": [
    "## Implementation\n",
    "Our goal is to find the minimum point of a certain function. In this case, the function is  $$ f(x,y) = x² + y² + 1.$$\n",
    "\n",
    "Thus, the algorithm will work with 2 dimensions positions arrays and the fitness value will be the Z-coordinate. Also, we know that our target is to find the coordinates $[0,0]$ which is the minimum of $f(x,y)$.￼"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.5\n",
    "c1 = 0.8\n",
    "c2 = 0.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(position):\n",
    "    f = position[0] ** 2 + position[1] ** 2 + 1\n",
    "    return f"
   ]
  },
  {
   "source": [
    "### Particle Class\n",
    "\n",
    "The __init__() method is automatically called whenever an object is instantiated. It performs four initializations:\n",
    "\n",
    "1. When a Particle is initiated automatically we sort 2 position limited in range $[minx,maxx]$. \n",
    "2. The pbest_position (which is the best individual position of that particle) is initiated with the initial position, \n",
    "3. As we’re looking for the minimum value, the pbest_value is initiated with +inf (could be any larger value). \n",
    "4. The initial velocity is set to zero.\n",
    "\n",
    "It’s also defined a method __str__() just to print the actual position and the best individual value. \n",
    "\n",
    "The move() method add the positional vector and the dimensions’ velocity calculated in the searches as we gonna see ahead.\n",
    "\n",
    "The method getFitness() computes the fitness of the current particle, but also updates the pbest value and position.￼\n",
    "\n",
    "The updateVelocity() method uses the equation (1).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle():\n",
    "    def __init__(self, dim = 1, minx = 0, maxx = 1):\n",
    "        self.dims = dim\n",
    "        self.position = np.random.uniform(low=minx, high=maxx, size=dim)\n",
    "        self.pbest_position = self.position\n",
    "        self.pbest_value = float('inf')\n",
    "        self.velocity = np.zeros(dim)\n",
    "\n",
    "    def __str__(self):\n",
    "        print(\"I am at \", self.position, \" my pbest is \", self.pbest_position)\n",
    "    \n",
    "    def move(self):\n",
    "        self.position = self.position + self.velocity\n",
    "\n",
    "    def getFitness(self):\n",
    "        current = fitness(self.position)\n",
    "        if (current < self.pbest_value):\n",
    "            self.pbest_value = current\n",
    "            self.pbest_position = self.position\n",
    "        return current\n",
    "    \n",
    "    def updateVelocity(self, best=None, w=0.1, c1=1, c2=1):\n",
    "        if best is None: \n",
    "            best = self\n",
    "        self.velocity = (w*self.velocity) + \\\n",
    "               (c1*random.random()) * (self.pbest_position - self.position) + \\\n",
    "               (c2*random.random()) * (best.pbest_position - self.position)"
   ]
  },
  {
   "source": [
    "### PSO Class\n",
    "\n",
    "Search Space\n",
    "\n",
    "The Search Space is the entity which controls the algorithm routine. In this implementation, it is responsible to keep all the particles, calculate the best global value and set the best global position. In resume, it encapsulate all principal steps.\n",
    "\n",
    "Main loop (optimize)\n",
    "\n",
    "In all iterations at first, for each particle, the current fitness is computed and , if neccesary, the best global is updated. Afterwards, the particle will calculate its new velocity and moves to a new position. The last line just print out the best result found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self, dims, numOfBoids, numOfEpochs):\n",
    "        self.swarm_list = [Particle(dims, -50, 50) for i in range(numOfBoids)]\n",
    "        self.numOfEpochs = numOfEpochs\n",
    "        self.best = self.swarm_list[0]\n",
    "\n",
    "    def optimize(self):\n",
    "        for epoch in range(self.numOfEpochs):\n",
    "            for particle in self.swarm_list:\n",
    "                current_fitness = particle.getFitness() \n",
    "\n",
    "                if particle.pbest_value < self.best.pbest_value:\n",
    "                    self.best = particle\n",
    "                \n",
    "                particle.updateVelocity(self.best, w, c1, c2)\n",
    "                particle.move()\n",
    "        print('Epoch: {0} | Best position: [{1}] | Best known value: {2}'.format(epoch, self.best.pbest_position, self.best.pbest_value))\n",
    "\n",
    "    def plotData(self):\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        for particle in self.swarm_list :\n",
    "            x.append(particle.pbest_position[0])\n",
    "            y.append(particle.pbest_position[1])\n",
    "            z.append(particle.pbest_value)\n",
    "        \n",
    "        plt.plot(x,y,z,'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 49 | Best position: [[2.02837940e-07 1.01581207e-07]] | Best known value: 1.0000000000000515\n"
     ]
    }
   ],
   "source": [
    "pso = PSO(dims=2, numOfBoids=30, numOfEpochs=50)\n",
    "pso.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2911da8f330f4f0fb2fdf40d600f9558"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Here is the grid range\n",
    "u = np.linspace(-5, 5, 500)\n",
    "v = np.linspace(-5, 5, 500)\n",
    "U,V = np.meshgrid(u,v)    \n",
    "UV = [ [u_i, v_j] for u_i,v_j in zip(U,V) ]\n",
    "z = [fitness(pos) for pos in UV ]\n",
    "Z = np.array(z)\n",
    "Z = Z.reshape(500,500)\n",
    "    \n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax.plot_surface(U, V, Z.T)\n",
    "ax.contour(U, V, Z.T,zdir='z', offset=-0.5)\n",
    "pso.plotData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other fitness functions\n",
    "def fitness(position): # Parabola\n",
    "    dims = len(position)\n",
    "    f = 0\n",
    "    for i in range(dims):\n",
    "        f = f + particle.position[i] ** 2\n",
    "    return f\n",
    "\n",
    "\n",
    "def fitness(position): #Rastrigin\n",
    "    dims = len(position)\n",
    "    k = 10\n",
    "    f = 0\n",
    "    for i in range(dims):\n",
    "        f = f + (position[i] ** 2 - k * np.cos(2 * np.pi * position[i]))\n",
    "    f = f + dims * k\n",
    "    return f\n",
    "\n",
    "def fitness(position): #Schwefel 7\n",
    "    dims = len(position)\n",
    "    f = 0\n",
    "    for i in range(dims):\n",
    "        f = f - position[i] * np.sin(np.sqrt(np.abs(position[i])))\n",
    "    return f"
   ]
  }
 ]
}